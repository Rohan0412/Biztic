{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8c3944f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import re\n",
    "import xlsxwriter\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from flask import Flask\n",
    "from flask import request\n",
    "from flask import render_template\n",
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b33465ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to MYSQL Database\n",
    "connection = mysql.connector.connect(host='192.168.12.102',\n",
    "            database='vonly_data_feed_us_staging',\n",
    "            user='vonly-agent',\n",
    "            password='a714fded-311c-4215-8b8b-5df4086e264b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16684e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def token(text):\n",
    "    # Remove everything except normal alphabets and numbers\n",
    "    cleaned_text = re.sub(r'[^a-zA-Z0-9]', ' ', text)\n",
    "    \n",
    "    # Tokenize the cleaned text\n",
    "    tokens = cleaned_text.split()\n",
    "    result =\"\"\n",
    "    for a in tokens:\n",
    "        result = result + a\n",
    "    result = result.lower()\n",
    "    for i in range(50):\n",
    "        result = result.replace(\"pt\"+str(i),\"part\"+str(i))\n",
    "        result = result.replace(\"p\"+str(i),\"part\"+str(i))\n",
    "        result = result.replace(\"partone\",\"part1\")\n",
    "        result = result.replace(\"parttwo\",\"part2\")\n",
    "        result = result.replace(\"partthree\",\"part3\")\n",
    "        result = result.replace(\"partfour\",\"part4\")\n",
    "        result = result.replace(\"partfive\",\"part5\")\n",
    "        result = result.replace(\"volume\",\"vol\")\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5dacd43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_v_id():\n",
    "    query100 = \"\"\" \n",
    "                    SELECT DISTINCT(t.vonly_asset_id) \n",
    "                    FROM tv_ids t \n",
    "                    WHERE t.scope='tv_season' AND\n",
    "                    t.platform NOT IN ('Amazon Movies & TV','WB MPM-VVId','YouTube','WB UPC')\n",
    "    \"\"\"\n",
    "\n",
    "    df100 = pd.read_sql_query(query100, connection)\n",
    "    \n",
    "    return df100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b055fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_var_name(var):\n",
    "    for name, value in globals().items():\n",
    "        if value is var:\n",
    "            return name\n",
    "\n",
    "def make_excel(data):\n",
    "    df = pd.DataFrame(data) \n",
    "    x = get_var_name(data)\n",
    "    df.to_excel(\"{}.xlsx\".format(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd2735ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(i):\n",
    "    query0 = \"\"\" \n",
    "                    SELECT * \n",
    "                    FROM tv_ids ti \n",
    "                    WHERE \n",
    "                    ti.scope='tv_season' \n",
    "                    AND ti.vonly_asset_id='{}'\n",
    "                    AND platform NOT IN ('Amazon Movies & TV','WB UPC','YouTube')\n",
    "    \"\"\".format(i)\n",
    "\n",
    "    df0 = pd.read_sql_query(query0, connection)\n",
    "    \n",
    "    return df0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc5da521",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_season_metadata(df0):\n",
    "    res1 = pd.DataFrame()  # Initialize an empty DataFrame\n",
    "\n",
    "    for portal_item_id, Platform in zip(df0['portal_item_id'], df0['platform']):\n",
    "        query1 = \"\"\"\n",
    "        SELECT ti.vonly_asset_id,ti.title season_name,ti.portal_item_id season_portal_item_id,ti.num season_no,\n",
    "                                                t.description,t.distributed_by,t.distributed_by_parent,t.produced_by,t.produced_by_parent,\n",
    "                                                t.us_theater_release_date,t.director,t.actors,t.writers,t.producers,\n",
    "                                                t.runtime,t.num season_no2, ti.platform, \n",
    "                                                (select count(1) from tv_ids tii where tii.scope='tv_season' and tii.vonly_asset_id=ti.vonly_asset_id and tii.platform=ti.platform) va_count\n",
    "                                                FROM vonly_data_feed_us_staging.tv_ids ti\n",
    "                                                INNER JOIN sandbox.tvshows t ON ti.id=t.vonly_id AND ti.region=t.region \n",
    "                                                 WHERE\n",
    "                                                ti.scope='tv_season' AND ti.platform NOT IN ('amazon movies & tv') AND  \n",
    "                                                ti.portal_item_id='{0}' and ti.platform='{1}' \n",
    "\n",
    "        \"\"\".format(portal_item_id, Platform)\n",
    "    \n",
    "        df1 = pd.read_sql_query(query1, connection)\n",
    "         \n",
    "        res1 = pd.concat([res1, df1], ignore_index=True)\n",
    "        \n",
    "    return res1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7aec1011",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_episode_details(df0):\n",
    "    \n",
    "    res2 = []\n",
    "    \n",
    "    for portal_item_id, Platform in zip(df0['portal_item_id'], df0['platform']):\n",
    "        query2 = \"\"\"\n",
    "        SELECT ti.vonly_asset_id,ti.title season_name,ti.portal_item_id season_portal_item_id,ti.num season_no,\n",
    "                                                t.description,t.distributed_by,t.distributed_by_parent,t.produced_by,t.produced_by_parent,\n",
    "                                                t.us_theater_release_date,t.director,t.actors,t.writers,t.producers,\n",
    "                                                t.runtime,t.num season_no2,tie.title episode_name,tie.portal_item_id episode_portal_item_id, tie.num episode_no, ti.platform, \n",
    "                                                (select count(1) from tv_ids tii where tii.scope='tv_season' and tii.vonly_asset_id=ti.vonly_asset_id and tii.platform=ti.platform) va_count\n",
    "                                                FROM vonly_data_feed_us_staging.tv_ids ti\n",
    "                                                INNER JOIN sandbox.tvshows t ON ti.id=t.vonly_id AND ti.region=t.region \n",
    "                                                LEFT OUTER JOIN vonly_data_feed_us_staging.tv_id_mappings tim ON ti.id=tim.season_vonly_id\n",
    "                                                LEFT OUTER JOIN  vonly_data_feed_us_staging.tv_ids tie ON tim.episode_vonly_id=tie.id  AND tie.scope='tv_episode'\n",
    "                                                 WHERE\n",
    "                                                ti.scope='tv_season' AND ti.platform NOT IN ('Amazon Movies & TV','WB UPC','YouTube') AND \n",
    "                                               ti.portal_item_id='{0}' and ti.platform='{1}' \n",
    "                                               ORDER BY CAST(tie.num AS SIGNED)\n",
    "\n",
    "        \"\"\".format(portal_item_id,Platform)\n",
    "              \n",
    "        df2 = pd.read_sql_query(query2, connection)\n",
    "        res2.append(df2)\n",
    "        \n",
    "    return res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d28c27a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metadata_validation(res):\n",
    "    \n",
    "    a = res[res['platform']  == 'AppleTVApp']\n",
    "    i = res[res['platform']  == 'iTunes']\n",
    "    am = res[res['platform']  == 'Amazon Prime Video']\n",
    "    v = res[res['platform']  == 'VUDU']\n",
    "    g = res[res['platform']  == 'Google Play']\n",
    "\n",
    "    if i.shape[0] != 0:\n",
    "        master = i.head(1)\n",
    "    elif v.shape[0] != 0:\n",
    "        master = v.head(1)\n",
    "    elif g.shape[0] != 0:\n",
    "        master = g.head(1)\n",
    "    elif am.shape[0] != 0:\n",
    "        master = am.head(1)\n",
    "    elif a.shape[0] != 0:\n",
    "        master = a.head(1)\n",
    "        \n",
    "    mapping_list = []\n",
    "    id_ = 0\n",
    "\n",
    "    for _, row1 in res.iterrows():\n",
    "        id_ += 1\n",
    "\n",
    "        count = 0\n",
    "        mapped = 0\n",
    "\n",
    "        matching_points = {\n",
    "            'id': id_,\n",
    "            'season': 0,\n",
    "            'season_no':row1['season_no'],\n",
    "            'season_no_1': '',\n",
    "            'title': 0,\n",
    "            'title_name': row1['season_name'],\n",
    "            'title_name_1': '',\n",
    "            'director': 0,\n",
    "            'director_name': row1['director'],\n",
    "            'director_name_1':'' ,\n",
    "            'producers': 0,\n",
    "            'producer_name': row1['producers'],\n",
    "            'producer_name_1':'' ,\n",
    "            'portal_item_id': 0,\n",
    "            'portal_item_id_': row1['season_portal_item_id'],\n",
    "            'portal_item_id_1':'' ,\n",
    "            'writers': 0,\n",
    "            'writer_name': row1['writers'],\n",
    "            'writer_name_1':'' ,\n",
    "            'runtime': 0,\n",
    "            'runtime_': row1['runtime'],\n",
    "            'runtime_1': '',\n",
    "            'count': count,\n",
    "            'mapped': mapped,\n",
    "        }\n",
    "\n",
    "        for _, row2 in master.iterrows():\n",
    "# 1\n",
    "            if not pd.isnull(row1['season_no']) and not pd.isnull(row2['season_no']) and row1['season_no'] == row2['season_no']:\n",
    "                matching_points['season'] = 1\n",
    "            elif pd.isnull(row1['season_no']) and pd.isnull(row2['season_no']):\n",
    "                matching_points['season'] = 0\n",
    "            matching_points['season_no_1'] = row2['season_no']\n",
    "\n",
    "# 2\n",
    "            if not pd.isnull(row1['season_name']) and not pd.isnull(row2['season_name']):\n",
    "                m = token(row1['season_name'])\n",
    "                n = token(row2['season_name'])\n",
    "                if m >= n and m.find(n) != -1:\n",
    "                    matching_points['title'] = 1\n",
    "                elif n > m and n.find(m)!= -1:\n",
    "                    matching_points['title'] = 1\n",
    "            elif pd.isnull(row1['season_name']) and pd.isnull(row2['season_name']):\n",
    "                matching_points['title'] = 0\n",
    "            matching_points['title_name_1'] = row2['season_name']\n",
    "\n",
    "# 3\n",
    "            if not pd.isnull(row1['director']) and not pd.isnull(row2['director']):\n",
    "                m = token(row1['director'])\n",
    "                n = token(row2['director'])\n",
    "                if m >= n and m.find(n) != -1:\n",
    "                    matching_points['director'] = 1\n",
    "                elif n > m and n.find(m)!= -1:\n",
    "                    matching_points['director'] = 1\n",
    "            elif pd.isnull(row1['director']) and pd.isnull(row2['director']):\n",
    "                matching_points['director'] = 0\n",
    "            matching_points['director_name_1'] = row2['director']\n",
    "\n",
    "# 4\n",
    "            if not pd.isnull(row1['producers']) and not pd.isnull(row2['producers']):\n",
    "                m = token(row1['producers'])\n",
    "                n = token(row2['producers'])\n",
    "                if m >= n and m.find(n) != -1:\n",
    "                    matching_points['producers'] = 1\n",
    "                elif n > m and n.find(m)!= -1:\n",
    "                    matching_points['producers'] = 1\n",
    "            elif pd.isnull(row1['producers']) and pd.isnull(row2['producers']):\n",
    "                matching_points['producers'] = 0\n",
    "            matching_points['producer_name_1'] = row2['producers']\n",
    "\n",
    "# 5\n",
    "            if not pd.isnull(row1['season_portal_item_id']) and not pd.isnull(row2['season_portal_item_id']):\n",
    "                m = token(row1['season_portal_item_id'])\n",
    "                n = token(row2['season_portal_item_id'])\n",
    "                if m >= n and m.find(n) != -1:\n",
    "                    matching_points['portal_item_id'] = 1\n",
    "                elif n > m and n.find(m)!= -1:\n",
    "                    matching_points['portal_item_id'] = 1\n",
    "            elif pd.isnull(row1['season_portal_item_id']) and pd.isnull(row2['season_portal_item_id']):\n",
    "                matching_points['portal_item_id'] = 0\n",
    "            matching_points['portal_item_id_1'] = row2['season_portal_item_id']\n",
    "\n",
    "# 6\n",
    "            if not pd.isnull(row1['writers']) and not pd.isnull(row2['writers']):\n",
    "                m = token(row1['writers'])\n",
    "                n = token(row2['writers'])\n",
    "                if m >= n and m.find(n) != -1:\n",
    "                    matching_points['writers'] = 1\n",
    "                elif n > m and n.find(m)!= -1:\n",
    "                    matching_points['writers'] = 1\n",
    "            elif pd.isnull(row1['writers']) and pd.isnull(row2['writers']):\n",
    "                matching_points['writers'] = 0\n",
    "            matching_points['writer_name_1'] = row2['writers']\n",
    "\n",
    "# 7\n",
    "            if not pd.isnull(row1['runtime']) and not pd.isnull(row2['runtime']):\n",
    "                m = token(row1['runtime'])\n",
    "                n = token(row2['runtime'])\n",
    "                if m >= n and m.find(n) != -1:\n",
    "                    matching_points['runtime'] = 1\n",
    "                elif n > m and n.find(m)!= -1:\n",
    "                    matching_points['runtime'] = 1\n",
    "            elif pd.isnull(row1['runtime']) and pd.isnull(row2['runtime']):\n",
    "                matching_points['runtime'] = 0\n",
    "            matching_points['runtime_1'] = row2['runtime']\n",
    "\n",
    "            count = matching_points['season'] + matching_points['title'] + matching_points['director'] + matching_points['producers'] + matching_points['portal_item_id'] + matching_points['writers'] + matching_points['runtime']\n",
    "\n",
    "        mapped = 1 if count >= 3 else 0\n",
    "\n",
    "        matching_points['count'] = count\n",
    "        matching_points['mapped'] = mapped\n",
    "\n",
    "        mapping_list.append(matching_points)\n",
    "\n",
    "    return mapping_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5746941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def episode_validation1(res2):\n",
    "    \n",
    "#     for x in res2:\n",
    "#         #print(x['platform'][0])\n",
    "#         if x['platform'][0] == 'iTunes':\n",
    "#             master = x\n",
    "#             break\n",
    "#         elif x['platform'][0] == 'VUDU':\n",
    "#             master = x\n",
    "#             break\n",
    "#         elif x['platform'][0] == 'Google Play':\n",
    "#             master = x\n",
    "#             break\n",
    "#         elif x['platform'][0] == 'Amazon Prime Video':\n",
    "#             master = x\n",
    "#             break\n",
    "#         elif x['platform'][0] == 'AppleTVApp':\n",
    "#             master = x\n",
    "#             break\n",
    "        \n",
    "# #     cnt=0\n",
    "\n",
    "#     mapping_list = []\n",
    "#     id_ = 0\n",
    " \n",
    "#     for r in res2:  \n",
    "        \n",
    "#         count = 0\n",
    "#         mapped = 0\n",
    "\n",
    "#         matching_points = {\n",
    "#             'id': 0,\n",
    "#             'vonly_asset_id_dest':'',\n",
    "#             'vonly_asset_id_source':'',\n",
    "#             'season_no_dest':'',\n",
    "#             'season_no_source':'',\n",
    "#             'season_name_dest':'',\n",
    "#             'season_name_1_source':'',\n",
    "#             'episode_platform_dest': '',\n",
    "#             'episode_platform_source':'',\n",
    "#             'episode_portal_item_id_dest': '',\n",
    "#             'episode_portal_item_id_source':'',\n",
    "#             'episodes': 0,\n",
    "#             'episode_no_dest':'',\n",
    "#             'episode_no_source': '',\n",
    "#             'episode_names': 0,\n",
    "#             'episode_name_dest': '',\n",
    "#             'episode_name_source': '',\n",
    "#             'count': 0,\n",
    "#             'mapped': 0,\n",
    "#         }\n",
    "\n",
    "#         for _, row1 in r.iterrows():\n",
    "            \n",
    "#             if row1['episode_name'] == None or row1['episode_name'] == '' or row1['episode_name'] == 'None' :\n",
    "#                         continue\n",
    "            \n",
    "#             for _, row2 in master.iterrows():\n",
    "                \n",
    "#                 matching_points = {\n",
    "#                     'id': 0,\n",
    "                     \n",
    "#                     'vonly_asset_id_dest':'',\n",
    "#                     'vonly_asset_id_source':'',\n",
    "                     \n",
    "#                     'season_no_dest':'',\n",
    "#                     'season_no_source':'',\n",
    "                     \n",
    "#                     'season_name_dest':'',\n",
    "#                     'season_name_source':'',\n",
    "                     \n",
    "#                     'episode_platform_dest': '',\n",
    "#                     'episode_platform_source':'',\n",
    "                     \n",
    "#                     'episode_portal_item_id_dest': '',\n",
    "#                     'episode_portal_item_id_source':'',\n",
    "\n",
    "#                     'episode_no_dest':'',\n",
    "#                     'episode_no_source': '',\n",
    "                     \n",
    "#                     'episode_names': 0,\n",
    "#                     'episode_name_dest': '',\n",
    "#                     'episode_name_source': '',\n",
    "                     \n",
    "#                     'count': 0,\n",
    "#                     'mapped': 0,\n",
    "#                 }\n",
    "              \n",
    "# # 1\n",
    "#                 if row1['episode_no'] == row2['episode_no']:\n",
    "#                     id_ += 1\n",
    "#                     matching_points['id'] = id_\n",
    "                    \n",
    "# #                     cnt = cnt+1\n",
    "# #                     print(cnt,row2['episode_name'],row1['episode_name'])\n",
    "                   \n",
    "#                     matching_points['episode_no_dest'] = row1['episode_no']\n",
    "#                     matching_points['episode_no_source'] = row2['episode_no']\n",
    "#                     print( row2['episode_name'])\n",
    "#                     if row2['episode_name'] == None or row2['episode_name'] == '' or row2['episode_name'] == 'None' :\n",
    "#                         continue\n",
    "#                     v = row2['episode_name'].lower()\n",
    "#                     plt2= v.find(\"pilot\")\n",
    "#                     u = row1['episode_name'].lower()\n",
    "#                     plt= u.find(\"pilot\")\n",
    "\n",
    "# # 2\n",
    "#                     if not pd.isnull(row1['episode_name']) and not pd.isnull(row2['episode_name']) and (plt2 == -1 and plt2 == -1):\n",
    "#                         m = token(row1['episode_name'])\n",
    "#                         n = token(row2['episode_name'])\n",
    "#                         if m >= n and m.find(n) != -1:\n",
    "#                             count+=1\n",
    "#                         elif n > m and n.find(m)!= -1:\n",
    "#                             count+=1\n",
    "\n",
    "#                     matching_points['episode_name_dest'] = row1['episode_name']\n",
    "#                     matching_points['episode_name_source'] = row2['episode_name']\n",
    "                    \n",
    "#                     matching_points['vonly_asset_id_dest'] = row1['vonly_asset_id']\n",
    "#                     matching_points['vonly_asset_id_source'] = row2['vonly_asset_id']\n",
    "                    \n",
    "#                     matching_points['season_no_dest'] = row1['season_no']\n",
    "#                     matching_points['season_no_source'] = row2['season_no']\n",
    "                    \n",
    "#                     matching_points['season_name_dest'] = row1['season_name']\n",
    "#                     matching_points['season_name_source'] = row2['season_name']\n",
    "                    \n",
    "#                     matching_points['episode_platform_dest'] = row1['platform']\n",
    "#                     matching_points['episode_platform_source'] = row2['platform']\n",
    "                    \n",
    "#                     matching_points['episode_portal_item_id_dest'] = row1['episode_portal_item_id']\n",
    "#                     matching_points['episode_portal_item_id_source'] = row2['episode_portal_item_id']\n",
    "                    \n",
    "#                     matching_points['episode_names'] = count\n",
    "\n",
    "#                     mapped = 1 if count >= 5 else 0\n",
    "\n",
    "#                     matching_points['count'] = count\n",
    "#                     matching_points['mapped'] = mapped\n",
    "\n",
    "\n",
    "#                     mapping_list.append(matching_points)\n",
    "\n",
    "#     return mapping_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d9b2165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# def episode_validation1(res2):\n",
    "#     mapping_list = []\n",
    "#     id_ = 0\n",
    "#     platform_found = False\n",
    "\n",
    "#     for r in res2:\n",
    "#         if isinstance(r, pd.DataFrame) and 'platform' in r.columns:  \n",
    "#             platforms = r['platform'].tolist()  \n",
    "#             if platforms:  \n",
    "#                 platform = platforms[0]  \n",
    "#                 if platform in ['iTunes', 'VUDU', 'Google Play', 'Amazon Prime Video', 'AppleTVApp']:\n",
    "#                     master = r\n",
    "#                     platform_found = True\n",
    "#                     break\n",
    "#                 if pd.isnull(r['platform']) or r['platform'] == '':\n",
    "#                     continue\n",
    "#         elif isinstance(r, pd.Series) and 'platform' in r.index:  \n",
    "#             platform = r['platform']  \n",
    "#             if platform in ['iTunes', 'VUDU', 'Google Play', 'Amazon Prime Video', 'AppleTVApp']:\n",
    "#                 master = pd.DataFrame(r).T  \n",
    "#                 platform_found = True\n",
    "#                 break\n",
    "#             if pd.isnull(r['platform']) or r['platform'] == '':\n",
    "#                 continue\n",
    "\n",
    "#     if not platform_found:\n",
    "#         print(\"No valid platform found in res2\")\n",
    "\n",
    "#     for r in res2:\n",
    "#         count = 0\n",
    "#         mapped = 0\n",
    "\n",
    "#         for _, row1 in r.iterrows():\n",
    "#             if pd.isnull(row1['episode_name']) or row1['episode_name'] == '':\n",
    "#                 continue\n",
    "\n",
    "#             for _, row2 in master.iterrows():\n",
    "#                 matching_points = {\n",
    "#                     'id': id_,\n",
    "#                     'vonly_asset_id_dest': row1['vonly_asset_id'],\n",
    "#                     'vonly_asset_id_source': row2['vonly_asset_id'],\n",
    "#                     'season_no_dest': row1['season_no'],\n",
    "#                     'season_no_source': row2['season_no'],\n",
    "#                     'season_name_dest': row1['season_name'],\n",
    "#                     'season_name_source': row2['season_name'],\n",
    "#                     'episode_platform_dest': row1['platform'],\n",
    "#                     'episode_platform_source': row2['platform'],\n",
    "#                     'episode_portal_item_id_dest': row1['episode_portal_item_id'],\n",
    "#                     'episode_portal_item_id_source': row2['episode_portal_item_id'],\n",
    "#                     'episode_no_dest': row1['episode_no'],\n",
    "#                     'episode_no_source': row2['episode_no'],\n",
    "#                     'episode_names': 0,\n",
    "#                     'episode_name_dest': row1['episode_name'],\n",
    "#                     'episode_name_source': row2['episode_name'],\n",
    "#                     'count': 0,\n",
    "#                     'mapped': 0,\n",
    "#                 }\n",
    "\n",
    "#                 if row1['episode_no'] == row2['episode_no']:\n",
    "#                     id_ += 1\n",
    "                    \n",
    "#                     matching_points['id'] = id_\n",
    "                    \n",
    "# #                     cnt = cnt+1\n",
    "# #                     print(cnt,row2['episode_name'],row1['episode_name'])\n",
    "                   \n",
    "#                     matching_points['episode_no_dest'] = row1['episode_no']\n",
    "#                     matching_points['episode_no_source'] = row2['episode_no']\n",
    "\n",
    "\n",
    "#                     if not pd.isnull(row2['episode_name']):\n",
    "#                         v = row2['episode_name'].lower()\n",
    "#                         plt2 = v.find(\"pilot\")\n",
    "#                         u = row1['episode_name'].lower()\n",
    "#                         plt = u.find(\"pilot\")\n",
    "\n",
    "#                         if plt2 == -1 and plt2 == -1:\n",
    "#                             m = token(row1['episode_name'])\n",
    "#                             n = token(row2['episode_name'])\n",
    "#                             if m >= n and m.find(n) != -1:\n",
    "#                                 count += 1\n",
    "#                             elif n > m and n.find(m) != -1:\n",
    "#                                 count += 1\n",
    "                                \n",
    "                    \n",
    "#                     matching_points['episode_name_dest'] = row1['episode_name']\n",
    "#                     matching_points['episode_name_source'] = row2['episode_name']\n",
    "                    \n",
    "#                     matching_points['vonly_asset_id_dest'] = row1['vonly_asset_id']\n",
    "#                     matching_points['vonly_asset_id_source'] = row2['vonly_asset_id']\n",
    "                    \n",
    "#                     matching_points['season_no_dest'] = row1['season_no']\n",
    "#                     matching_points['season_no_source'] = row2['season_no']\n",
    "                    \n",
    "#                     matching_points['season_name_dest'] = row1['season_name']\n",
    "#                     matching_points['season_name_source'] = row2['season_name']\n",
    "                    \n",
    "#                     matching_points['episode_platform_dest'] = row1['platform']\n",
    "#                     matching_points['episode_platform_source'] = row2['platform']\n",
    "                    \n",
    "#                     matching_points['episode_portal_item_id_dest'] = row1['episode_portal_item_id']\n",
    "#                     matching_points['episode_portal_item_id_source'] = row2['episode_portal_item_id']\n",
    "                    \n",
    "#                     matching_points['episode_names'] = count\n",
    "\n",
    "#                     mapped = 1 if count >= 5 else 0\n",
    "\n",
    "#                     matching_points['count'] = count\n",
    "#                     matching_points['mapped'] = mapped\n",
    "\n",
    "\n",
    "#                     mapping_list.append(matching_points)\n",
    "\n",
    "\n",
    "#     return mapping_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "df984cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def episode_validation1(res2):\n",
    "    mapping_list = []\n",
    "    id_ = 0\n",
    "    platform_found = False\n",
    "\n",
    "    for r in res2:\n",
    "        if isinstance(r, pd.DataFrame) and 'platform' in r.columns:  \n",
    "            platforms = r['platform'].tolist()  \n",
    "            if platforms:  \n",
    "                platform = platforms[0]  \n",
    "                if platform in ['iTunes', 'VUDU', 'Google Play', 'Amazon Prime Video', 'AppleTVApp']:\n",
    "                    master = r\n",
    "                    platform_found = True\n",
    "                    break\n",
    "                if pd.isnull(r['platform']) or r['platform'] == '':\n",
    "                    continue\n",
    "        elif isinstance(r, pd.Series) and 'platform' in r.index:  \n",
    "            platform = r['platform']  \n",
    "            if platform in ['iTunes', 'VUDU', 'Google Play', 'Amazon Prime Video', 'AppleTVApp']:\n",
    "                master = pd.DataFrame(r).T  \n",
    "                platform_found = True\n",
    "                break\n",
    "            if pd.isnull(r['platform']) or r['platform'] == '':\n",
    "                continue\n",
    "\n",
    "    if not platform_found:\n",
    "        print(\"No valid platform found in res2\")\n",
    "\n",
    "    batch_size = 50000\n",
    "\n",
    "    for batch_start in range(0, len(res2), batch_size):\n",
    "        batch_end = min(batch_start + batch_size, len(res2))\n",
    "        batch_res2 = res2[batch_start:batch_end]\n",
    "\n",
    "        for r in batch_res2:\n",
    "            count = 0\n",
    "            mapped = 0\n",
    "\n",
    "            for _, row1 in r.iterrows():\n",
    "                if pd.isnull(row1['episode_name']) or row1['episode_name'] == '':\n",
    "                    continue\n",
    "\n",
    "                for _, row2 in master.iterrows():\n",
    "                    matching_points = {\n",
    "                        'id': id_,\n",
    "                        'vonly_asset_id_dest': row1['vonly_asset_id'],\n",
    "                        'vonly_asset_id_source': row2['vonly_asset_id'],\n",
    "                        'season_no_dest': row1['season_no'],\n",
    "                        'season_no_source': row2['season_no'],\n",
    "                        'season_name_dest': row1['season_name'],\n",
    "                        'season_name_source': row2['season_name'],\n",
    "                        'episode_platform_dest': row1['platform'],\n",
    "                        'episode_platform_source': row2['platform'],\n",
    "                        'episode_portal_item_id_dest': row1['episode_portal_item_id'],\n",
    "                        'episode_portal_item_id_source': row2['episode_portal_item_id'],\n",
    "                        'episode_no_dest': row1['episode_no'],\n",
    "                        'episode_no_source': row2['episode_no'],\n",
    "                        'episode_names': 0,\n",
    "                        'episode_name_dest': row1['episode_name'],\n",
    "                        'episode_name_source': row2['episode_name'],\n",
    "                        'count': 0,\n",
    "                        'mapped': 0,\n",
    "                    }\n",
    "\n",
    "                    if row1['episode_no'] == row2['episode_no']:\n",
    "                        id_ += 1\n",
    "                        \n",
    "                        matching_points['id'] = id_\n",
    "                        \n",
    "                        matching_points['episode_no_dest'] = row1['episode_no']\n",
    "                        matching_points['episode_no_source'] = row2['episode_no']\n",
    "\n",
    "\n",
    "                        if not pd.isnull(row2['episode_name']):\n",
    "                            v = row2['episode_name'].lower()\n",
    "                            plt2 = v.find(\"pilot\")\n",
    "                            u = row1['episode_name'].lower()\n",
    "                            plt = u.find(\"pilot\")\n",
    "\n",
    "                            if plt2 == -1 and plt == -1:\n",
    "                                m = token(row1['episode_name'])\n",
    "                                n = token(row2['episode_name'])\n",
    "                                if m >= n and m.find(n) != -1:\n",
    "                                    count += 1\n",
    "                                elif n > m and n.find(m) != -1:\n",
    "                                    count += 1\n",
    "                                    \n",
    "                        \n",
    "                        matching_points['episode_name_dest'] = row1['episode_name']\n",
    "                        matching_points['episode_name_source'] = row2['episode_name']\n",
    "                        \n",
    "                        matching_points['vonly_asset_id_dest'] = row1['vonly_asset_id']\n",
    "                        matching_points['vonly_asset_id_source'] = row2['vonly_asset_id']\n",
    "                        \n",
    "                        matching_points['season_no_dest'] = row1['season_no']\n",
    "                        matching_points['season_no_source'] = row2['season_no']\n",
    "                        \n",
    "                        matching_points['season_name_dest'] = row1['season_name']\n",
    "                        matching_points['season_name_source'] = row2['season_name']\n",
    "                        \n",
    "                        matching_points['episode_platform_dest'] = row1['platform']\n",
    "                        matching_points['episode_platform_source'] = row2['platform']\n",
    "                        \n",
    "                        matching_points['episode_portal_item_id_dest'] = row1['episode_portal_item_id']\n",
    "                        matching_points['episode_portal_item_id_source'] = row2['episode_portal_item_id']\n",
    "                        \n",
    "                        matching_points['episode_names'] = count\n",
    "\n",
    "                        mapped = 1 if count >= 5 else 0\n",
    "\n",
    "                        matching_points['count'] = count\n",
    "                        matching_points['mapped'] = mapped\n",
    "\n",
    "\n",
    "                        mapping_list.append(matching_points)\n",
    "\n",
    "\n",
    "    return mapping_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f6bc3b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vds = get_v_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f3dddeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_id = vds['vonly_asset_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ce4aadaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "204998"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(v_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c26cba34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n",
      "No valid platform found in res2\n"
     ]
    },
    {
     "ename": "DatabaseError",
     "evalue": "Execution failed on sql: \n        SELECT ti.vonly_asset_id,ti.title season_name,ti.portal_item_id season_portal_item_id,ti.num season_no,\n                                                t.description,t.distributed_by,t.distributed_by_parent,t.produced_by,t.produced_by_parent,\n                                                t.us_theater_release_date,t.director,t.actors,t.writers,t.producers,\n                                                t.runtime,t.num season_no2,tie.title episode_name,tie.portal_item_id episode_portal_item_id, tie.num episode_no, ti.platform, \n                                                (select count(1) from tv_ids tii where tii.scope='tv_season' and tii.vonly_asset_id=ti.vonly_asset_id and tii.platform=ti.platform) va_count\n                                                FROM vonly_data_feed_us_staging.tv_ids ti\n                                                INNER JOIN sandbox.tvshows t ON ti.id=t.vonly_id AND ti.region=t.region \n                                                LEFT OUTER JOIN vonly_data_feed_us_staging.tv_id_mappings tim ON ti.id=tim.season_vonly_id\n                                                LEFT OUTER JOIN  vonly_data_feed_us_staging.tv_ids tie ON tim.episode_vonly_id=tie.id  AND tie.scope='tv_episode'\n                                                 WHERE\n                                                ti.scope='tv_season' AND ti.platform NOT IN ('Amazon Movies & TV','WB UPC','YouTube') AND \n                                               ti.portal_item_id='B0921KHPXM' and ti.platform='Amazon Prime Video' \n                                               ORDER BY CAST(tie.num AS SIGNED)\n\n        \n2013: Lost connection to MySQL server during query\nunable to rollback",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInterfaceError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\sql.py:2202\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[1;34m(self, sql, params)\u001b[0m\n\u001b[0;32m   2201\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2202\u001b[0m     cur\u001b[38;5;241m.\u001b[39mexecute(sql, \u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m   2203\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cur\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\mysql\\connector\\cursor.py:617\u001b[0m, in \u001b[0;36mMySQLCursor.execute\u001b[1;34m(self, operation, params, multi)\u001b[0m\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_result(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mcmd_query(stmt))\n\u001b[0;32m    618\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InterfaceError \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\mysql\\connector\\opentelemetry\\context_propagation.py:77\u001b[0m, in \u001b[0;36mwith_context_propagation.<locals>.wrapper\u001b[1;34m(cnx, *args, **kwargs)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m OTEL_ENABLED \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cnx\u001b[38;5;241m.\u001b[39motel_context_propagation:\n\u001b[1;32m---> 77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m method(cnx, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     79\u001b[0m current_span \u001b[38;5;241m=\u001b[39m trace\u001b[38;5;241m.\u001b[39mget_current_span()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\mysql\\connector\\connection.py:843\u001b[0m, in \u001b[0;36mMySQLConnection.cmd_query\u001b[1;34m(self, query, raw, buffered, raw_as_string)\u001b[0m\n\u001b[0;32m    842\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 843\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_result(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_cmd(ServerCmd\u001b[38;5;241m.\u001b[39mQUERY, query))\n\u001b[0;32m    844\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ProgrammingError \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\mysql\\connector\\connection.py:465\u001b[0m, in \u001b[0;36mMySQLConnection._send_cmd\u001b[1;34m(self, command, argument, packet_number, packet, expect_response, compressed_packet_number)\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 465\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_socket\u001b[38;5;241m.\u001b[39mrecv()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\mysql\\connector\\network.py:631\u001b[0m, in \u001b[0;36mMySQLSocket.recv\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get packet from the MySQL server comm channel.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_netbroker\u001b[38;5;241m.\u001b[39mrecv(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maddress)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\mysql\\connector\\network.py:231\u001b[0m, in \u001b[0;36mNetworkBrokerPlain.recv\u001b[1;34m(self, sock, address)\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;66;03m# Read the header of the MySQL packet\u001b[39;00m\n\u001b[1;32m--> 231\u001b[0m     header \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recv_chunk(sock, size\u001b[38;5;241m=\u001b[39mPACKET_HEADER_LENGTH)\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;66;03m# Pull the payload length and sequence id\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\mysql\\connector\\network.py:178\u001b[0m, in \u001b[0;36mNetworkBrokerPlain._recv_chunk\u001b[1;34m(self, sock, size)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m read \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m size \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 178\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InterfaceError(errno\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2013\u001b[39m)\n\u001b[0;32m    179\u001b[0m pkt_view \u001b[38;5;241m=\u001b[39m pkt_view[read:]\n",
      "\u001b[1;31mInterfaceError\u001b[0m: 2013: Lost connection to MySQL server during query",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mSSLEOFError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\mysql\\connector\\network.py:163\u001b[0m, in \u001b[0;36mNetworkBrokerPlain._send_pkt\u001b[1;34m(self, sock, address, pkt)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 163\u001b[0m     sock\u001b[38;5;241m.\u001b[39msendall(pkt)\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\ssl.py:1274\u001b[0m, in \u001b[0;36mSSLSocket.sendall\u001b[1;34m(self, data, flags)\u001b[0m\n\u001b[0;32m   1273\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m count \u001b[38;5;241m<\u001b[39m amount:\n\u001b[1;32m-> 1274\u001b[0m     v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(byte_view[count:])\n\u001b[0;32m   1275\u001b[0m     count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m v\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\ssl.py:1243\u001b[0m, in \u001b[0;36mSSLSocket.send\u001b[1;34m(self, data, flags)\u001b[0m\n\u001b[0;32m   1240\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1241\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to send() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1242\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1243\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mwrite(data)\n\u001b[0;32m   1244\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mSSLEOFError\u001b[0m: EOF occurred in violation of protocol (_ssl.c:2427)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\sql.py:2206\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[1;34m(self, sql, params)\u001b[0m\n\u001b[0;32m   2205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcon\u001b[38;5;241m.\u001b[39mrollback()\n\u001b[0;32m   2207\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m inner_exc:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\mysql\\connector\\connection.py:1270\u001b[0m, in \u001b[0;36mMySQLConnection.rollback\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1268\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_rows()\n\u001b[1;32m-> 1270\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_query(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mROLLBACK\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\mysql\\connector\\connection.py:1282\u001b[0m, in \u001b[0;36mMySQLConnection._execute_query\u001b[1;34m(self, query)\u001b[0m\n\u001b[0;32m   1281\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_unread_result()\n\u001b[1;32m-> 1282\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcmd_query(query)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\mysql\\connector\\opentelemetry\\context_propagation.py:77\u001b[0m, in \u001b[0;36mwith_context_propagation.<locals>.wrapper\u001b[1;34m(cnx, *args, **kwargs)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m OTEL_ENABLED \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cnx\u001b[38;5;241m.\u001b[39motel_context_propagation:\n\u001b[1;32m---> 77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m method(cnx, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     79\u001b[0m current_span \u001b[38;5;241m=\u001b[39m trace\u001b[38;5;241m.\u001b[39mget_current_span()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\mysql\\connector\\connection.py:843\u001b[0m, in \u001b[0;36mMySQLConnection.cmd_query\u001b[1;34m(self, query, raw, buffered, raw_as_string)\u001b[0m\n\u001b[0;32m    842\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 843\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_result(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_cmd(ServerCmd\u001b[38;5;241m.\u001b[39mQUERY, query))\n\u001b[0;32m    844\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ProgrammingError \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\mysql\\connector\\connection.py:455\u001b[0m, in \u001b[0;36mMySQLConnection._send_cmd\u001b[1;34m(self, command, argument, packet_number, packet, expect_response, compressed_packet_number)\u001b[0m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 455\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_socket\u001b[38;5;241m.\u001b[39msend(\n\u001b[0;32m    456\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_protocol\u001b[38;5;241m.\u001b[39mmake_command(command, packet \u001b[38;5;129;01mor\u001b[39;00m argument),\n\u001b[0;32m    457\u001b[0m         packet_number,\n\u001b[0;32m    458\u001b[0m         compressed_packet_number,\n\u001b[0;32m    459\u001b[0m     )\n\u001b[0;32m    460\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\mysql\\connector\\network.py:621\u001b[0m, in \u001b[0;36mMySQLSocket.send\u001b[1;34m(self, payload, packet_number, compressed_packet_number)\u001b[0m\n\u001b[0;32m    620\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Send `payload` to the MySQL server.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 621\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_netbroker\u001b[38;5;241m.\u001b[39msend(\n\u001b[0;32m    622\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock,\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maddress,\n\u001b[0;32m    624\u001b[0m     payload,\n\u001b[0;32m    625\u001b[0m     packet_number\u001b[38;5;241m=\u001b[39mpacket_number,\n\u001b[0;32m    626\u001b[0m     compressed_packet_number\u001b[38;5;241m=\u001b[39mcompressed_packet_number,\n\u001b[0;32m    627\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\mysql\\connector\\network.py:219\u001b[0m, in \u001b[0;36mNetworkBrokerPlain.send\u001b[1;34m(self, sock, address, payload, packet_number, compressed_packet_number)\u001b[0m\n\u001b[0;32m    218\u001b[0m     payload \u001b[38;5;241m=\u001b[39m payload[offset:]\n\u001b[1;32m--> 219\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_pkt(\n\u001b[0;32m    220\u001b[0m     sock,\n\u001b[0;32m    221\u001b[0m     address,\n\u001b[0;32m    222\u001b[0m     struct\u001b[38;5;241m.\u001b[39mpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<I\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(payload))[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m3\u001b[39m]\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;241m+\u001b[39m struct\u001b[38;5;241m.\u001b[39mpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<B\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pktnr)\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;241m+\u001b[39m payload,\n\u001b[0;32m    225\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\mysql\\connector\\network.py:165\u001b[0m, in \u001b[0;36mNetworkBrokerPlain._send_pkt\u001b[1;34m(self, sock, address, pkt)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 165\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OperationalError(\n\u001b[0;32m    166\u001b[0m         errno\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2055\u001b[39m, values\u001b[38;5;241m=\u001b[39m(address, _strioerror(err))\n\u001b[0;32m    167\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[1;31mOperationalError\u001b[0m: 2055: Lost connection to MySQL server at '192.168.12.102:3306', system error: 8 EOF occurred in violation of protocol (_ssl.c:2427)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m df0 \u001b[38;5;241m=\u001b[39m get_data(i)\n\u001b[0;32m      6\u001b[0m res \u001b[38;5;241m=\u001b[39m get_season_metadata(df0)\n\u001b[1;32m----> 8\u001b[0m res2 \u001b[38;5;241m=\u001b[39m get_episode_details(df0)\n\u001b[0;32m      9\u001b[0m res_2 \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m res2:\n",
      "Cell \u001b[1;32mIn[22], line 23\u001b[0m, in \u001b[0;36mget_episode_details\u001b[1;34m(df0)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m portal_item_id, Platform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(df0[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mportal_item_id\u001b[39m\u001b[38;5;124m'\u001b[39m], df0[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplatform\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[0;32m      6\u001b[0m     query2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124m    SELECT ti.vonly_asset_id,ti.title season_name,ti.portal_item_id season_portal_item_id,ti.num season_no,\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124m                                            t.description,t.distributed_by,t.distributed_by_parent,t.produced_by,t.produced_by_parent,\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m \n\u001b[0;32m     21\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(portal_item_id,Platform)\n\u001b[1;32m---> 23\u001b[0m     df2 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_sql_query(query2, connection)\n\u001b[0;32m     24\u001b[0m     res2\u001b[38;5;241m.\u001b[39mappend(df2)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res2\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\sql.py:469\u001b[0m, in \u001b[0;36mread_sql_query\u001b[1;34m(sql, con, index_col, coerce_float, params, parse_dates, chunksize, dtype, dtype_backend)\u001b[0m\n\u001b[0;32m    466\u001b[0m     dtype_backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pandasSQL_builder(con) \u001b[38;5;28;01mas\u001b[39;00m pandas_sql:\n\u001b[1;32m--> 469\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pandas_sql\u001b[38;5;241m.\u001b[39mread_query(\n\u001b[0;32m    470\u001b[0m         sql,\n\u001b[0;32m    471\u001b[0m         index_col\u001b[38;5;241m=\u001b[39mindex_col,\n\u001b[0;32m    472\u001b[0m         params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[0;32m    473\u001b[0m         coerce_float\u001b[38;5;241m=\u001b[39mcoerce_float,\n\u001b[0;32m    474\u001b[0m         parse_dates\u001b[38;5;241m=\u001b[39mparse_dates,\n\u001b[0;32m    475\u001b[0m         chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[0;32m    476\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    477\u001b[0m         dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    478\u001b[0m     )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\sql.py:2266\u001b[0m, in \u001b[0;36mSQLiteDatabase.read_query\u001b[1;34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype, dtype_backend)\u001b[0m\n\u001b[0;32m   2255\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_query\u001b[39m(\n\u001b[0;32m   2256\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   2257\u001b[0m     sql,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2264\u001b[0m     dtype_backend: DtypeBackend \u001b[38;5;241m|\u001b[39m Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2265\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Iterator[DataFrame]:\n\u001b[1;32m-> 2266\u001b[0m     cursor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute(sql, params)\n\u001b[0;32m   2267\u001b[0m     columns \u001b[38;5;241m=\u001b[39m [col_desc[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m col_desc \u001b[38;5;129;01min\u001b[39;00m cursor\u001b[38;5;241m.\u001b[39mdescription]\n\u001b[0;32m   2269\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\sql.py:2211\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[1;34m(self, sql, params)\u001b[0m\n\u001b[0;32m   2207\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m inner_exc:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[0;32m   2208\u001b[0m     ex \u001b[38;5;241m=\u001b[39m DatabaseError(\n\u001b[0;32m   2209\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecution failed on sql: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msql\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mexc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124munable to rollback\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2210\u001b[0m     )\n\u001b[1;32m-> 2211\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01minner_exc\u001b[39;00m\n\u001b[0;32m   2213\u001b[0m ex \u001b[38;5;241m=\u001b[39m DatabaseError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecution failed on sql \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msql\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2214\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[1;31mDatabaseError\u001b[0m: Execution failed on sql: \n        SELECT ti.vonly_asset_id,ti.title season_name,ti.portal_item_id season_portal_item_id,ti.num season_no,\n                                                t.description,t.distributed_by,t.distributed_by_parent,t.produced_by,t.produced_by_parent,\n                                                t.us_theater_release_date,t.director,t.actors,t.writers,t.producers,\n                                                t.runtime,t.num season_no2,tie.title episode_name,tie.portal_item_id episode_portal_item_id, tie.num episode_no, ti.platform, \n                                                (select count(1) from tv_ids tii where tii.scope='tv_season' and tii.vonly_asset_id=ti.vonly_asset_id and tii.platform=ti.platform) va_count\n                                                FROM vonly_data_feed_us_staging.tv_ids ti\n                                                INNER JOIN sandbox.tvshows t ON ti.id=t.vonly_id AND ti.region=t.region \n                                                LEFT OUTER JOIN vonly_data_feed_us_staging.tv_id_mappings tim ON ti.id=tim.season_vonly_id\n                                                LEFT OUTER JOIN  vonly_data_feed_us_staging.tv_ids tie ON tim.episode_vonly_id=tie.id  AND tie.scope='tv_episode'\n                                                 WHERE\n                                                ti.scope='tv_season' AND ti.platform NOT IN ('Amazon Movies & TV','WB UPC','YouTube') AND \n                                               ti.portal_item_id='B0921KHPXM' and ti.platform='Amazon Prime Video' \n                                               ORDER BY CAST(tie.num AS SIGNED)\n\n        \n2013: Lost connection to MySQL server during query\nunable to rollback"
     ]
    }
   ],
   "source": [
    "ans=[]\n",
    "ans_1 = []\n",
    "for i in v_id:\n",
    "    df0 = get_data(i)\n",
    "\n",
    "    res = get_season_metadata(df0)\n",
    "\n",
    "    res2 = get_episode_details(df0)\n",
    "    res_2 = []\n",
    "    for y in res2:\n",
    "        m = y.drop_duplicates(subset = ['episode_name'])\n",
    "        res_2.append(m)\n",
    "\n",
    "    u = episode_validation1(res_2)\n",
    "    ans_1 += u\n",
    "    ans = ans + (metadata_validation(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "31b69b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_excel(ans)\n",
    "make_excel(ans_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3369be38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91492e05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
